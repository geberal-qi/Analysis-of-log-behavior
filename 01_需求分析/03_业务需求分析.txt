目标：获取日志中的pv、uv、跳出率和转化率
     细化需求：
      1.nginx每天采集一个日志记录文件access_20170215.log 
         eg:日志文件位置 hadoop01/nginx/log 目录下
         
      2.在每天的凌晨2点对上一天的日志文件进行数据分析
         数据分析系统在spark服务器集群
         2.1 数据采集
	       每天凌晨两点触发数据采集脚本，从hadoop01/nginx/log 目录下采集到上一天的日志文件
	       存储到HDFS系统
	 2.2 完成业务需求
	       获取日志中的pv、uv、跳出率和转化率
	 2.3 将分析的结果保存
	       分析结果保存到mysql数据库
	 2.4 报表开发
	       完成网站运营指标的展示

自定义指标
根据业务需求，对基础指标加减乘除，组合成新的指标，进一步分析。
热图
直观了解用户对网页上内容的点击情况，根据点击热度优化产品和运营。
实时分析
分钟级监控活动效果，发现产品内的异常情况。支持预判和预警。
漏斗
通过漏斗分析，找到关键流失环节并进行优化，支持多维度和分群分析。
智能转化分析
只要确定转化目标，就可以智能展现所有行为路径和占比
留存
支持用户留存分析、功能留存分析以及自定义留存分析，全方位提高留存。
留存智能分析
一键智能发现产品的留存魔法数字，轻松提高新用户的留存。
用户分群
将不同的用户分组分析，更有针对性地进行用户运营。
用户细查
清楚而明晰地看清每一个用户的属性信息、行为轨迹以及具体操作。

多维度下钻分析，打通行为分析闭环，数据分析更系统


在大数据时代，企业的生产、销售、经营、管理逐渐由技术驱动转型为数据驱动，在这一过程中数据的重要性不言而喻。借助于云计算、大数据等技术的发展，我们通过收集、处理、分析、展示数据，重新认识了周围的世界，重新定义了规则与价值，数据驱动的企业能够更全面地认知现状、更精准地把握趋势。而在企业日常运行积累的海量数据中，日志是其中最易获得、覆盖面最广同时也是最有价值的数据之一。

日志指用户、服务器、网络设备、操作系统、数据库、应用软件等产生的各类数据，它的核心概念是时序递增的事件序列。基于时间与事件这两个基本要素，我们可以在日志中追溯过去的记录、记录现在的状态、探寻未来的趋势，这就是日志所蕴含的价值。根据日志的不同来源与类型，典型的日志应用场景可以划分为以下三类：
・ 运维日志：记录设备、系统的运行情况，用于监控服务器状态、定位排查故障、分析性能瓶颈等；
・ 用户日志：记录业务信息，例如页面的PV、UV、停留时间等，用于了解业务运营状况、分析用户行为特征等；
・ 安全日志：记录服务器、防火墙等设备的日志，供安全审计系统使用，用于监控系统安全、进行可信取证等。

传统日志分析工具往往局限于单一的应用场景，功能较为简单，难以满足运维、产品、运营、管理者等不同角色的不同需求。且随着业务量的增长，日志文件在容量、类型、产生速度等方面都成倍地增长，对于系统在处理速度、并发量、分析维度等方面的要求也越来越高，传统的日志分析工具越来越难以适应实际应用的需求。

随着大数据技术的日渐发展成熟，新的日志分析工具应运而生。将大数据技术与云计算技术相结合，托管式日志分析服务综合了大数据的大体量、多样性、时效性等特性与云计算强可靠性、高可用性、即取即用与经济性等优势，克服了传统工具在功能与性能上的限制，解决了自行搭建系统门槛高且运维困难的问题，是一种经济高效的解决方案。


